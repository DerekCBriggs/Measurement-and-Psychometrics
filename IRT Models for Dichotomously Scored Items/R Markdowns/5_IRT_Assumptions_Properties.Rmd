---
title: "Assumptions and Properties of IRT Models"
author: "Derek Briggs"
date: "EDUC 8720"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: show
  pdf_document:
    toc: true
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Overview

IRT models rest on several key **assumptions** and have important **properties** that distinguish them from classical test theory. Understanding these is essential for proper application and interpretation.

| Assumptions | Properties |
|:------------|:-----------|
| Local Independence | Parameter Invariance |
| Appropriate Dimensionality | Scale Indeterminacy |
| Functional Form (ICC shape) | |
| Continuous latent variable | |

---

## Assumption 1: Local Independence

### Definition

Item responses are **statistically independent, conditional on the latent variable** $\theta$.

Put differently: the only reason item responses are correlated is due to their common dependence on $\theta$.

### Mathematical Expression

This assumption gives us the important result:

$$P(X_{1p} = 1 \text{ and } X_{2p} = 1 | \theta_p) = P(X_{1p} = 1 | \theta_p) \times P(X_{2p} = 1 | \theta_p)$$

More generally, for a full response pattern:

$$P(X_1, X_2, \ldots, X_I | \theta) = \prod_{i=1}^{I} P(X_i | \theta)$$

This is the same assumption made in factor analysis. For multidimensional IRT, we assume item responses are independent conditional on **all** dimensions of $\theta$ included in the model.

### Demonstration

```{r local-independence-demo}
# 3PL probability function
calc_prob <- function(theta, a, b, c) {
  c + (1 - c) * exp(a * (theta - b)) / (1 + exp(a * (theta - b)))
}

# Two items
a <- c(1.5, 1.2)
b <- c(-0.5, 0.5)
c <- c(0.2, 0.15)

# For a person with theta = 0
theta <- 0
p1 <- calc_prob(theta, a[1], b[1], c[1])
p2 <- calc_prob(theta, a[2], b[2], c[2])

cat("P(X1 = 1 | theta = 0) =", round(p1, 3), "\n")
cat("P(X2 = 1 | theta = 0) =", round(p2, 3), "\n")
cat("\nUnder local independence:\n")
cat("P(X1 = 1 AND X2 = 1 | theta = 0) =", round(p1 * p2, 3), "\n")
```

### What Causes Violations of Local Independence?

1. **Multidimensionality**: Test measures more than one latent trait
2. **Item chaining**: Answer to one item depends on previous item
3. **Testlet effects**: Items share common stimulus (e.g., reading passage)
4. **Speededness**: Time pressure creates dependence among later items
5. **Method effects**: Similar item formats create additional covariance

### Checking Local Independence

```{r check-li, fig.width=8, fig.height=5}
library(mirt)

# Load example data
forma <- read.csv("../Data/pset1_formA.csv")
forma <- forma[, 1:15]

# Fit model
mod <- mirt(forma, 1, itemtype = "2PL", verbose = FALSE)

# Residual correlations can indicate local dependence
residuals_ld <- residuals(mod, type = "LD")

# Visualize (upper triangle of matrix)
library(ggplot2)

# Convert to long format for plotting
ld_matrix <- as.matrix(residuals_ld)
ld_df <- expand.grid(Item1 = 1:15, Item2 = 1:15)
ld_df$LD <- as.vector(ld_matrix)
ld_df <- ld_df[ld_df$Item1 < ld_df$Item2, ]

ggplot(ld_df, aes(x = factor(Item1), y = factor(Item2), fill = LD)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0,
                       name = "LD\nStatistic") +
  labs(x = "Item", y = "Item", title = "Local Dependence Check: Residual Correlations") +
  theme_minimal()
```

Large positive values suggest items may be locally dependent.

---

## Quick Aside: Useful Probability Rules

These rules are essential for understanding IRT:

1. **Complement Rule**: $P(A) = 1 - P(\neg A)$
   - Probability of A is 1 minus the probability of A not happening

2. **Multiplication Rule (Independence)**: $P(A \text{ and } B) = P(A) \times P(B)$
   - When A and B are independent
   - This is the **joint probability** of A and B occurring
   - Local independence allows us to use this for item responses

3. **Conditional Probability**: $P(A|B) = \frac{P(A \text{ and } B)}{P(B)}$
   - Probability of A given that B happened

4. **Bayes' Rule**: $P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}$

### Application to Response Patterns

```{r prob-rules-demo}
# Calculate probability of response pattern (1, 0, 1) for theta = 0.5
theta <- 0.5
items <- data.frame(a = c(1, 1.5, 1.2), b = c(-1, 0, 1), c = c(0.2, 0.2, 0.15))

probs <- sapply(1:3, function(i) calc_prob(theta, items$a[i], items$b[i], items$c[i]))

cat("Item probabilities at theta = 0.5:\n")
cat("P(X1 = 1) =", round(probs[1], 3), "\n")
cat("P(X2 = 1) =", round(probs[2], 3), "\n")
cat("P(X3 = 1) =", round(probs[3], 3), "\n")

# Pattern (1, 0, 1)
pattern_prob <- probs[1] * (1 - probs[2]) * probs[3]
cat("\nP(X1=1, X2=0, X3=1 | theta=0.5) =", round(pattern_prob, 4), "\n")
```

---

## Assumption 2: Appropriate Dimensionality

### Definition

The model contains the **appropriate number of latent dimensions** to account for the covariance among items.

- For unidimensional IRT: One $\theta$ is sufficient
- For multidimensional IRT: Multiple $\theta$s are needed

### Key Points

- If a test is **multidimensional** and we fit only a single latent variable, this can cause **local item dependence**
- Dimensionality refers to the number of latent variables needed to model the response data
- This may or may not correspond to the hypothesized dimensionality of the theoretical construct
- Most IRT models used in practice are unidimensional

### Assessing Dimensionality

```{r dimensionality, fig.width=10, fig.height=5}
par(mfrow = c(1, 2))

# Eigenvalue plot (scree plot)
eigenvalues <- eigen(cor(forma))$values
plot(eigenvalues, type = "b", pch = 19,
     xlab = "Component Number", ylab = "Eigenvalue",
     main = "Scree Plot")
abline(h = 1, lty = 2, col = "red")

# Ratio of first to second eigenvalue
cat("First eigenvalue:", round(eigenvalues[1], 2), "\n")
cat("Second eigenvalue:", round(eigenvalues[2], 2), "\n")
cat("Ratio (1st/2nd):", round(eigenvalues[1]/eigenvalues[2], 2), "\n")

# Cumulative variance explained
cum_var <- cumsum(eigenvalues) / sum(eigenvalues)
plot(cum_var, type = "b", pch = 19,
     xlab = "Number of Components", ylab = "Cumulative Variance Explained",
     main = "Cumulative Variance", ylim = c(0, 1))
abline(h = 0.8, lty = 2, col = "red")

par(mfrow = c(1, 1))
```

**Guidelines:**

- A dominant first eigenvalue suggests unidimensionality
- Ratio of first to second eigenvalue > 3 often indicates essential unidimensionality
- But these are rough guidelines, not strict rules

---

## Assumption 3: Functional Form (ICC Shape)

### Definition

We assume that the probability of correct responses follows the **logistic form** (or normal ogive):

$$P(X_{ip} = 1 | \theta_p) = c_i + (1 - c_i) \frac{\exp(a_i(\theta_p - b_i))}{1 + \exp(a_i(\theta_p - b_i))}$$

### Key Characteristics

1. **Monotonically increasing** probability as a function of $\theta$
2. **S-shaped** (sigmoidal) curve
3. Described by the $a$, $b$, and $c$ parameters
4. Lower asymptote determined by $c$
5. Upper asymptote is 1 (or can be less with a 4PL model)

```{r icc-form, fig.width=10, fig.height=5}
theta <- seq(-4, 4, 0.1)

par(mfrow = c(1, 2))

# Standard ICC
plot(theta, calc_prob(theta, 1.5, 0, 0.2), type = "l", lwd = 3, col = "blue",
     xlab = expression(theta), ylab = expression(P(X == 1)),
     main = "Standard 3PL ICC Form",
     ylim = c(0, 1))
abline(h = c(0.2, 1), lty = 2, col = "gray")
text(-3, 0.25, "c (lower asymptote)", col = "gray40")

# What if ICC were NOT monotonic? (This would violate the assumption)
theta_range <- seq(-4, 4, 0.1)
non_monotonic <- 0.5 + 0.3 * sin(theta_range)  # Hypothetical non-monotonic

plot(theta_range, non_monotonic, type = "l", lwd = 3, col = "red",
     xlab = expression(theta), ylab = expression(P(X == 1)),
     main = "Hypothetical Non-Monotonic ICC\n(Would Violate Assumption)",
     ylim = c(0, 1))

par(mfrow = c(1, 1))
```

### Checking ICC Form with Empirical Plots

```{r empirical-icc, fig.width=10, fig.height=4}
# Compare model-implied ICC to empirical ICC
library(mirt)

par(mfrow = c(1, 3))

# Check item fit for 3 items
for (item in 1:3) {
  itemfit(mod, group.bins = 10, empirical.plot = item)
}

par(mfrow = c(1, 1))
```

If the empirical points deviate systematically from the model-implied curve, the functional form assumption may be violated.

---

## Property 1: Parameter Invariance

### Definition

If the model fits the data, **item parameter estimates should be the same regardless of the group used to estimate them**.

- We should get the same $a$, $b$, $c$ parameters whether we use high-ability or low-ability examinees
- Similarly, person parameters should be the same regardless of which items are used

### Why This Matters

| CTT | IRT |
|:----|:----|
| Item p-values depend on sample | Item parameters are invariant (if model fits) |
| Discrimination depends on sample variance | Discrimination is a stable property |
| Need matched samples for comparison | Can compare across different samples |

### Analogy: Linear Regression

In linear regression, we assume the slope and intercept are the same regardless of which subset of data we use to estimate them.

```{r invariance-demo, fig.width=10, fig.height=5}
set.seed(123)

# Generate population data
n <- 1000
x <- rnorm(n, 0, 1)
y <- 0.5 + 0.7 * x + rnorm(n, 0, 0.3)

# Split into "low" and "high" groups
low_group <- x < 0
high_group <- x >= 0

par(mfrow = c(1, 2))

# Full data
plot(x, y, pch = 16, col = rgb(0, 0, 0, 0.3),
     main = "Full Data", xlab = "X", ylab = "Y")
abline(lm(y ~ x), col = "blue", lwd = 2)

# Separate groups
plot(x[low_group], y[low_group], pch = 16, col = rgb(1, 0, 0, 0.5),
     xlim = range(x), ylim = range(y),
     main = "Low (Red) vs High (Blue) Groups", xlab = "X", ylab = "Y")
points(x[high_group], y[high_group], pch = 16, col = rgb(0, 0, 1, 0.5))
abline(lm(y[low_group] ~ x[low_group]), col = "red", lwd = 2, lty = 2)
abline(lm(y[high_group] ~ x[high_group]), col = "blue", lwd = 2, lty = 2)

par(mfrow = c(1, 1))

# Compare estimates
cat("Full data: slope =", round(coef(lm(y ~ x))[2], 3), "\n")
cat("Low group: slope =", round(coef(lm(y[low_group] ~ x[low_group]))[2], 3), "\n")
cat("High group: slope =", round(coef(lm(y[high_group] ~ x[high_group]))[2], 3), "\n")
```

### Checking Parameter Invariance in IRT

```{r check-invariance}
# Split sample by total score
total_scores <- rowSums(forma)
median_score <- median(total_scores)

low_ability <- forma[total_scores <= median_score, ]
high_ability <- forma[total_scores > median_score, ]

cat("Low ability group: n =", nrow(low_ability), "\n")
cat("High ability group: n =", nrow(high_ability), "\n")
```

```{r fit-groups, results='hide'}
# Fit models separately (note: this is for illustration - real invariance testing is more complex)
mod_low <- mirt(low_ability, 1, itemtype = "2PL", verbose = FALSE)
mod_high <- mirt(high_ability, 1, itemtype = "2PL", verbose = FALSE)
```

```{r compare-params, fig.width=10, fig.height=5}
# Extract parameters
coef_low <- coef(mod_low, simplify = TRUE, IRTpars = TRUE)$items
coef_high <- coef(mod_high, simplify = TRUE, IRTpars = TRUE)$items

par(mfrow = c(1, 2))

# Compare discrimination parameters
plot(coef_low[, 1], coef_high[, 1], pch = 19,
     xlab = "a (Low Ability Group)", ylab = "a (High Ability Group)",
     main = "Discrimination Parameter Comparison")
abline(0, 1, col = "red", lty = 2)

# Compare difficulty parameters
plot(coef_low[, 2], coef_high[, 2], pch = 19,
     xlab = "b (Low Ability Group)", ylab = "b (High Ability Group)",
     main = "Difficulty Parameter Comparison")
abline(0, 1, col = "red", lty = 2)

par(mfrow = c(1, 1))
```

**Note:** Perfect invariance is rarely achieved in practice due to:
- Sampling error
- Scale differences between groups
- Potential model misfit

---

## Property 2: Scale Indeterminacy

### The Problem

Because we cannot observe $a$, $b$, $c$, or $\theta$ directly, and they occur together in the model, there is **inherent indeterminacy** in the scale.

Consider the expression $a_i(\theta_p - b_i)$.

Now define new values:

- $b_i^* = (b_i + k_1) / k_2$
- $\theta_p^* = (\theta_p + k_1) / k_2$
- $a_i^* = k_2 \times a_i$
- $c_i^* = c_i$

It will be true that: $a_i(\theta_p - b_i) = a_i^*(\theta_p^* - b_i^*)$

**So which set of parameters should we use?**

### Demonstration

```{r scale-indet-demo}
# Original parameters
a <- 1.5
b <- 0.5
theta <- 1.0

# Original value
original <- a * (theta - b)
cat("Original: a*(theta - b) =", a, "* (", theta, "-", b, ") =", original, "\n\n")

# Transform with k1 = 1, k2 = 2
k1 <- 1
k2 <- 2

a_star <- k2 * a
b_star <- (b + k1) / k2
theta_star <- (theta + k1) / k2

transformed <- a_star * (theta_star - b_star)
cat("Transformed parameters:\n")
cat("a* =", a_star, "\n")
cat("b* =", b_star, "\n")
cat("theta* =", theta_star, "\n")
cat("a**(theta* - b*) =", a_star, "* (", theta_star, "-", b_star, ") =", transformed, "\n")
```

### Resolving Scale Indeterminacy

There are two main approaches:

#### 1. Item-Side Anchoring

- Place constraints on item parameters (e.g., mean item difficulty = 0)
- Freely estimate the $\theta$ distribution
- More common in Rasch modeling and in Europe

#### 2. Person-Side Anchoring

- Fix distribution of $\theta$ to have mean = 0 and SD = 1
- Freely estimate item parameters
- More common in US and in achievement testing

```{r anchoring-demo}
# Example: Different software may use different anchoring
# mirt uses person-side anchoring by default

# Get theta estimates
theta_estimates <- fscores(mod, method = "EAP")

cat("Theta distribution (person-side anchored):\n")
cat("Mean:", round(mean(theta_estimates), 3), "\n")
cat("SD:", round(sd(theta_estimates), 3), "\n")

# Get item parameters
item_params <- coef(mod, simplify = TRUE, IRTpars = TRUE)$items

cat("\nItem difficulty (b) distribution:\n")
cat("Mean b:", round(mean(item_params[, 2]), 3), "\n")
cat("SD of b:", round(sd(item_params[, 2]), 3), "\n")
```

### Practical Implications

1. **Comparing across studies**: Must ensure same scale/anchoring
2. **Linking**: Need anchor items or anchor persons to equate scales
3. **Interpretation**: The absolute value of $\theta$ is arbitrary; only relative positions matter

---

## Summary

### Assumptions

| Assumption | Description | Violation Consequences |
|:-----------|:------------|:-----------------------|
| Local Independence | Responses independent given $\theta$ | Biased parameter estimates |
| Dimensionality | Correct number of latent dimensions | Local dependence, poor fit |
| Functional Form | ICC follows logistic/normal ogive | Poor item fit |
| Continuous $\theta$ | Latent variable is continuous | (Rarely problematic) |

### Properties

| Property | Description | Practical Implication |
|:---------|:------------|:---------------------|
| Parameter Invariance | Parameters same across groups | Enables fair comparison |
| Scale Indeterminacy | Scale defined up to linear transform | Need anchoring conventions |

### Key Takeaways

1. **Local independence** is crucial - violations can seriously bias estimates
2. **Dimensionality** should be checked before fitting unidimensional models
3. **Parameter invariance** is a property, not an assumption - it holds if model fits
4. **Scale indeterminacy** means we need conventions to interpret parameters
5. Always check model assumptions before interpreting results!
